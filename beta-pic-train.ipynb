{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\beta$ -Pic b planet\n",
    "\n",
    "I'll try to obtain the same posteriors as found in the paper of [Sun et al](https://arxiv.org/pdf/2201.08506.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prior import prior_distributions\n",
    "from simulator import OrbitCreator\n",
    "from training import train_sbi\n",
    "\n",
    "import torch\n",
    "\n",
    "import orbitize\n",
    "from orbitize import read_input\n",
    "\n",
    "from lampe.data import H5Dataset\n",
    "from lampe.inference import * # Import all methods and their losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset with the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = read_input.read_file('{}/betaPic.csv'.format(orbitize.DATADIR))\n",
    "\n",
    "data_set = data_set[:-1] # Discard the  RV observation, don't know how to take it into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the priors\n",
    "The priors are defined as such \n",
    "$$\n",
    "\\begin{align*}\n",
    "a &\\sim \\log \\mathcal{U}(10,10^{4})\\\\\n",
    "e &\\sim \\mathcal{U}(10^{8}, 0.99)\\\\\n",
    "i &\\sim \\mathcal{U}(0,180)\\\\\n",
    "\\omega &\\sim \\mathcal{U}(0,360)\\\\\n",
    "\\Omega &\\sim \\mathcal{U}(0,360)\\\\\n",
    "\\tau &\\sim \\mathcal{U}(0,1)\\\\\n",
    "\\pi &\\sim \\mathcal{N}(56.95, 0.26) \\\\\n",
    "M_T &\\sim \\mathcal{N}(1.22,0.08)\\\\\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = prior_distributions(log_uniform_lower = torch.tensor(10.0), \n",
    "                            log_uniform_upper = torch.tensor(10**4),\n",
    "                            uniform_lower = torch.tensor([10e-8, 0.0, 0.0, 0.0, 0.0]), \n",
    "                            uniform_upper = torch.tensor([0.99, 180.0, 360.0, 360.0, 1.0]),\n",
    "                            gaussian_mean = torch.tensor([56.95, 1.22]), \n",
    "                            gaussian_std = torch.tensor([0.26, 0.08]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the simulator\n",
    "\n",
    "And test if it works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 39.571\n",
      "e: 0.368\n",
      "i: 49.861\n",
      "ω: 191.044\n",
      "Ω: 178.085\n",
      "τ: 0.248\n",
      "π: 56.776\n",
      "Mt: 1.262\n",
      "\n",
      " x:\n",
      "(1122.525, -1988.948)\n",
      "(1411.975, -1989.417)\n",
      "(1066.035, -2002.987)\n",
      "(1054.719, -1988.102)\n",
      "(1038.425, -1994.249)\n",
      "(1010.405, -1989.864)\n",
      "(1002.094, -1994.468)\n",
      "(1001.466, -2014.087)\n",
      "(989.278, -2016.897)\n",
      "(979.852, -2008.134)\n",
      "(1059.21, -1991.194)\n",
      "(1059.057, -1997.436)\n",
      "(995.189, -1996.606)\n",
      "(945.078, -1995.794)\n",
      "(945.098, -2000.134)\n",
      "(917.872, -1992.583)\n",
      "(917.881, -1998.01)\n",
      "(875.938, -1977.885)\n",
      "(875.414, -1998.351)\n",
      "(815.719, -1994.157)\n",
      "(815.713, -1990.89)\n",
      "(815.371, -1991.069)\n",
      "(811.567, -1991.199)\n",
      "(811.574, -1990.463)\n",
      "(811.401, -1990.978)\n",
      "(753.742, -1988.589)\n",
      "(728.394, -1983.964)\n",
      "(690.113, -1983.506)\n",
      "(684.982, -1979.579)\n",
      "(681.976, -1979.667)\n",
      "(676.665, -1979.589)\n",
      "(740.296, -1986.428)\n",
      "(502.691, -1957.646)\n",
      "(492.195, -1949.221)\n"
     ]
    }
   ],
   "source": [
    "simulator = OrbitCreator(data_set)\n",
    "\n",
    "thetas = prior.sample((1,))\n",
    "x = simulator(thetas)\n",
    "\n",
    "label_print = ['a', 'e', 'i', 'ω', 'Ω', 'τ', 'π', 'Mt']\n",
    "\n",
    "for label, theta_value in zip(label_print, thetas[0].tolist()):\n",
    "    print(f\"{label}: {theta_value:.3f}\")\n",
    "\n",
    "print(\"\\n x:\")\n",
    "for i in range(0, len(x[0]), 2):\n",
    "    x_coord = round(x[0][i].item(), 3)\n",
    "    y_coord = round(x[0][i+1].item(), 3)\n",
    "    print(f\"({x_coord}, {y_coord})\", end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = H5Dataset('Datasets/beta-pic-train.h5',\n",
    "                     batch_size=2048, shuffle=True)\n",
    "validset = H5Dataset('Datasets/beta-pic-val.h5',\n",
    "                     batch_size=2048)\n",
    "testset = H5Dataset('Datasets/beta-pic-test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the SBI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:21<00:00, 27.07s/epoch, loss=0.378, val_loss=0.372]\n"
     ]
    }
   ],
   "source": [
    "len_obs = len(data_set) * 2 # 2 coordinates per observation\n",
    "\n",
    "estimator = NRE(8, len_obs, hidden_features=[256]*5).cuda()\n",
    "\n",
    "train_sbi('NRE-test-adam', \n",
    "          estimator, \n",
    "          NRELoss, \n",
    "          trainset, \n",
    "          validset, \n",
    "          epochs = 512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
