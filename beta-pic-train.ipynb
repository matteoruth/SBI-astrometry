{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\beta$ -Pic b planet\n",
    "\n",
    "I'll try to obtain the same posteriors as found in the paper of [Sun et al](https://arxiv.org/pdf/2201.08506.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prior import prior_distributions\n",
    "from simulator import OrbitCreator\n",
    "from training import train_sbi\n",
    "\n",
    "import torch\n",
    "\n",
    "import orbitize\n",
    "from orbitize import read_input\n",
    "\n",
    "from lampe.data import H5Dataset\n",
    "from lampe.inference import * # Import all methods and their losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = read_input.read_file('{}/betaPic.csv'.format(orbitize.DATADIR))\n",
    "\n",
    "data_set = data_set[:-1] # Discard the  RV observation, don't know how to take it into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the priors\n",
    "The priors are defined as such \n",
    "$$\n",
    "\\begin{align*}\n",
    "a &\\sim \\log \\mathcal{U}(10,10^{4})\\\\\n",
    "e &\\sim \\mathcal{U}(10^{8}, 0.99)\\\\\n",
    "i &\\sim \\mathcal{U}(0,180)\\\\\n",
    "\\omega &\\sim \\mathcal{U}(0,360)\\\\\n",
    "\\Omega &\\sim \\mathcal{U}(0,360)\\\\\n",
    "\\tau &\\sim \\mathcal{U}(0,1)\\\\\n",
    "\\pi &\\sim \\mathcal{N}(56.95, 0.26) \\\\\n",
    "M_T &\\sim \\mathcal{N}(1.22,0.08)\\\\\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = prior_distributions(log_uniform_lower = torch.tensor(10.0), \n",
    "                            log_uniform_upper = torch.tensor(10**4),\n",
    "                            uniform_lower = torch.tensor([10e-8, 0.0, 0.0, 0.0, 0.0]), \n",
    "                            uniform_upper = torch.tensor([0.99, 180.0, 360.0, 360.0, 1.0]),\n",
    "                            gaussian_mean = torch.tensor([56.95, 1.22]), \n",
    "                            gaussian_std = torch.tensor([0.26, 0.08]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the simulator\n",
    "\n",
    "And test if it works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 19.097\n",
      "e: 0.872\n",
      "i: 143.785\n",
      "ω: 296.819\n",
      "Ω: 114.182\n",
      "τ: 0.267\n",
      "π: 57.408\n",
      "Mt: 1.199\n",
      "\n",
      " x:\n",
      "(-33.042, 1036.183)\n",
      "(-213.696, 1166.674)\n",
      "(2.233, 994.635)\n",
      "(8.531, 959.258)\n",
      "(18.718, 957.308)\n",
      "(36.111, 928.944)\n",
      "(41.008, 929.354)\n",
      "(41.461, 910.319)\n",
      "(48.353, 915.522)\n",
      "(54.841, 909.767)\n",
      "(6.623, 977.997)\n",
      "(5.396, 992.322)\n",
      "(44.872, 920.73)\n",
      "(74.746, 875.966)\n",
      "(74.813, 871.634)\n",
      "(90.791, 848.704)\n",
      "(90.846, 844.541)\n",
      "(115.632, 796.886)\n",
      "(115.041, 801.431)\n",
      "(148.611, 741.013)\n",
      "(148.608, 743.667)\n",
      "(148.797, 746.189)\n",
      "(150.863, 743.167)\n",
      "(150.865, 740.291)\n",
      "(150.955, 740.755)\n",
      "(181.201, 670.708)\n",
      "(193.733, 637.076)\n",
      "(211.498, 582.907)\n",
      "(213.727, 579.116)\n",
      "(215.026, 572.954)\n",
      "(217.306, 565.454)\n",
      "(187.922, 653.284)\n",
      "(248.554, 234.085)\n",
      "(244.742, 206.38)\n"
     ]
    }
   ],
   "source": [
    "simulator = OrbitCreator(data_set)\n",
    "\n",
    "thetas = prior.sample((1,))\n",
    "x = simulator(thetas)\n",
    "\n",
    "label_print = ['a', 'e', 'i', 'ω', 'Ω', 'τ', 'π', 'Mt']\n",
    "\n",
    "for label, theta_value in zip(label_print, thetas[0].tolist()):\n",
    "    print(f\"{label}: {theta_value:.3f}\")\n",
    "\n",
    "print(\"\\n x:\")\n",
    "for i in range(0, len(x[0]), 2):\n",
    "    x_coord = round(x[0][i].item(), 3)\n",
    "    y_coord = round(x[0][i+1].item(), 3)\n",
    "    print(f\"({x_coord}, {y_coord})\", end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = H5Dataset('Datasets/beta-pic-train.h5',\n",
    "                     batch_size=2048, shuffle=True)\n",
    "validset = H5Dataset('Datasets/beta-pic-val.h5',\n",
    "                     batch_size=2048)\n",
    "testset = H5Dataset('Datasets/beta-pic-test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the SBI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_obs = len(data_set)\n",
    "\n",
    "estimator = NRE(8, len_obs, hidden_features=[256]*5).cuda()\n",
    "\n",
    "train_sbi('NRE',\n",
    "          estimator, \n",
    "          NRELoss, \n",
    "          trainset, \n",
    "          validset, \n",
    "          epochs = 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
